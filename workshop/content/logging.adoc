## OpenShift ログ集約
このラボでは、OpenShiftのログ集約機能を触ってみます。

OpenShift の非常に重要な機能は、実行中の環境とアプリケーションポッドからログを収集して集約することです。
OpenShift には柔軟性のある *EFK* によるログ集約ソリューションが同梱されています。
*EFK* は、それぞれのソリューションの頭文字を集めたものです。( *E* lasticSearch、*F* luentd、*K* ibana)

クラスタの Logging コンポーネントは、Elasticsearch、Fluentd、Kibana（EFK）をベースにしています。
コレクターである Fluentd は、OpenShift クラスタ内の各ノードにデプロイされています。
これはすべてのノードとコンテナのログを収集し、Elasticsearch（ES）に書き込みます。
Kibana は一元化された Web UI で、ユーザーや管理者は集約されたデータを使ってリッチなビジュアライゼーションやダッシュボードを作成することができます。
管理者は、すべてのログを検索することができます。
アプリケーションの所有者や開発者は、プロジェクトに属するログへのアクセスを許可することができます。
EFK スタックは OpenShift の上で動作します。

[WARNING]
====
このラボでは、infra-nodes ラボを完了していることが必要です。
Logging スタックはそのラボで作成された `infra` ノードにインストールされます。
====

[NOTE]
====
詳細は、以下にあるOpenShiftの公式ドキュメントサイトに記載されています。:
 https://docs.openshift.com/container-platform/4.1/logging/efk-logging.html
====

[NOTE]
====
この演習は、ほぼすべて OpenShift の Web コンソールを使用して行われます。
ウェブコンソールとのやりとりはすべて、事実上バックグラウンドで API オブジェクトを作成または操作しています。
プロセスを完全に自動化したり、CLIや他のツールを使用して行うことも可能ですが、これらの方法は現時点では、この演習やドキュメントではカバーされていません。
====

### OpenShift Logging をデプロイする

OpenShift Container Platform Cluster Logging は、デフォルト構成で使用するように設計されており、中小規模の OpenShift Container Platform クラスタ向けに調整されています。
以降のインストール手順には、サンプルの Cluster Logging Custom Resource（CR）が含まれており、これを使用して Cluster Logging インスタンスを作成し、Cluster Logging の導入を構成することができます。

デフォルトの Cluster Logging インストールを使用する場合は、サンプルCRを直接使用できます。

配置をカスタマイズしたい場合は、必要に応じてサンプル CR に変更を加えます。
以下では、Cluster Logging インスタンスのインストール時に行うことができる構成、またはインストール後に変更することができる構成について説明します。
Cluster Logging Custom Resource の外でできる変更を含め、各コンポーネントでの作業の詳細については、「構成」のセクションを参照してください。

#### `openshift-logging` namespace を作成する

OpenShift Logging は、独自の名前空間 `openshift-logging` 内で実行されます。
この名前空間はデフォルトでは存在せず、Logging をインストールする前に作成する必要があります。
名前空間は yaml 形式で以下のように表されます。:

[source,yaml]
.openshift_logging_namespace.yaml
----
apiVersion: v1
kind: Namespace
metadata:
  name: openshift-logging
  annotations:
    openshift.io/node-selector: ""
  labels:
    openshift.io/cluster-logging: "true"
    openshift.io/cluster-monitoring: "true"
----

ネームスペースを作成するには、以下のコマンドを実行します。:

[source,bash,role="execute"]
----
oc create -f {{ HOME_PATH }}/support/openshift_logging_namespace.yaml
----


#### `Elasticsearch` と `Cluster Logging` Operator をクラスターにインストールする

`EFK` スタックをクラスタにインストールして設定するには、追加の Operator をインストールする必要があります。
これらは、クラスタ内から `Operator Hub` から GUI を介してインストールすることができます。

OpenShift で Operator を使用する際には、Operator を構成するいくつかの基本的な原理を理解しておくことが重要です。
`CustomResourceDefinion (CRD)` と `CustomResource (CR)` は、簡単に説明する 2 つの Kubernetes オブジェクトです。
`CRD` は、ジェネリックな事前定義された、データの構造体です。
Operator は、`CRD` で定義されたデータをどのように適用するかを理解します。
プログラミング的には、`CRD` はクラスに似ていると考えることができます。
`CustomResource (CR)` は、構造化されたデータが実際の値を持つ `CRD` の実際の実装です。
これらの値は、Operator がサービスを設定するときに使用するものです。
繰り返しになりますが、プログラミング用語では、`CR` はクラスのインスタンス化されたオブジェクトに似ています。

Operator を使用するための一般的なパターンは、まず Operator をインストールし、必要な `CRD` を作成します。
`CRD` が作成された後、どのように動作するか、何をインストールするか、何を設定するかを Operator に伝える `CR` を作成します。
openshift-logging　をインストールするには、このパターンに従います。

まず、OpenShift ClusterのGUIにログインします。
`{{ MASTER_URL }}`

その後、以下の手順に従ってください。:

1. Elasticsearch Operator のインストール:
  a. OpenShift コンソールから、 `Operators` → `OperatorHub` をクリックします。
  b. `Elasticsearch Operator` を、Operator リストから選択し、 `Install` をクリックします。
  c. `Create Operator Subscription` ページで、*Update Channel 4.2* を選択し、他のすべてのデフォルト設定をそのままに、`Subscribe`　をクリックします。
+
これにより、この OpenShift Container Platform クラスタを使用するすべてのユーザーとプロジェクトがこの Operator を利用できるようになります。

2. Cluster Logging Operator のインストール:
+
[NOTE]
====
`Cluster Logging` Operator を  `openshift-logging` ネームスペースにインストールする必要があります。
`openshift-logging` ネームスペースが前の手順で作成されたことを確認してください。
====

  a. OpenShift コンソールで、`Operators` → `OperatorHub` をクリックします。
  b. 利用可能な Operator のリストから `Cluster Logging` を選択し、`Install` をクリックする。
  c. `Create Operator Subscription` ページで、`Installation Mode` で、クラスタ上の特定の名前空間が選択されていることを確認し、`openshift-logging` を選択します。
     さらに、*select Update Channel 4.2* を選択し、他のすべてのデフォルトを残してから `Subscribe` をクリックします。

3. Operator のインストールを確認する。:

  a. `Operators` → `Installed Operators` のページに切り替える。

  b. `openshift-logging` プロジェクトが選択されていることを確認する。

  c. _Status_ 列で、緑色のチェックで、 `InstallSucceeded` もしくは `Copied` そして _Up to date_ のテキストが見えるはずです。
+
[NOTE]
====
インストール中に Operator が `Failed` ステータスを表示することがあります。
Operator が  `InstallSucceeded` メッセージを表示してインストールが完了した場合、`Failed` メッセージを無視しても問題ありません。
====

4. トラブルシューティング (オプショナル)
+
どちらかの Operator がインストールされているように表示されない場合は、さらにトラブルシューティングを行います。:
+
* Installed Operators ページの Copied タブで、Operator に Status of Copied が表示されている場合、これはインストールが進行中であり、期待される動作であることを示しています。
+
* Catalog → Operator Management ページに切り替え、Operator Subscriptions and Install Plans のタブで、ステータスの下に障害やエラーがないかどうかを確認します。
+
* Workloads → Pods のページに切り替えて、openshift-logging と openshift-operators プロジェクトで問題を報告している任意の Pod のログを確認します。


#### Logging `CustomResource (CR)` インスタンスを作成する

Operator を `CRD` と一緒にインストールしたので、Logging `CR` を作成して、Logging のインストールを開始します。
これは、Logging をインストールして設定する方法を定義します。

1. OpenShift Consoleで、`Administration` → `Custom Resource Definitions` ページに切り替えます。

2. `Custom Resource Definitions` のページで、 `ClusterLogging` をクリックする。

3. `Custom Resource Definition Overview` ページで、`Actions` メニューから `View Instances` を選択する。
+
[NOTE]
====
`404` のエラーが表示されても、慌てないでください。
Operator のインストールは成功したものの、Operator 自体のインストールが完了しておらず、 `CustomResourceDefinition` がまだ作成されていない可能性があります。
しばらく待ってからページを更新してください。
====
+
4. `Cluster Loggings` ページで、 `Create Cluster Logging` をクリックします。
+
[WARNING]
====
このステップに入る前に、`Deploying and Managing OpenShift Container Storage` モジュールを完了している必要があります。
`OCS` モジュールが完了していない場合は、エディタにコピーする前に、以下の `YAML` の `storageClassName: ocs-storagecluster-ceph-rbd` を `storageClassName: gp2` で置き換える必要があります。
====

5. `YAML` エディタで、コードを以下で置き換えます。:

[source,yaml]
.openshift_logging_cr.yaml
----
apiVersion: "logging.openshift.io/v1"
kind: "ClusterLogging"
metadata:
  name: "instance"
  namespace: "openshift-logging"
spec:
  managementState: "Managed"
  logStore:
    type: "elasticsearch"
    elasticsearch:
      nodeCount: 3
      storage:
         storageClassName: ocs-storagecluster-ceph-rbd
         size: 100Gi
      redundancyPolicy: "SingleRedundancy"
      nodeSelector:
        node-role.kubernetes.io/infra: ""
      resources:
        request:
          memory: 4G
  visualization:
    type: "kibana"
    kibana:
      replicas: 1
      nodeSelector:
        node-role.kubernetes.io/infra: ""
  curation:
    type: "curator"
    curator:
      schedule: "30 3 * * *"
      nodeSelector:
        node-role.kubernetes.io/infra: ""
  collection:
    logs:
      type: "fluentd"
      fluentd: {}
      nodeSelector:
        node-role.kubernetes.io/infra: ""
----

そして `Create` をクリックします。

#### Logging インストールを確認する

Logging が作成されたので、動作しているかどうかを確認してみましょう。

1. `Workloads` → `Pods` ページに移動します。

2. `openshift-logging` プロジェクトを選択します。

クラスタ Logging （Operator 自身）、Elasticsearch、Fluentd、Kibana　のポッドが表示されているはずです。

または、次のコマンドを使用してコマンドラインから検証することもできます。:

[source,bash,role="execute"]
----
oc get pods -n openshift-logging
----

最終的には、次のようなものが表示されるはずです。:

----
NAME                                            READY   STATUS    RESTARTS   AGE
cluster-logging-operator-cb795f8dc-xkckc        1/1     Running   0          32m
elasticsearch-cdm-b3nqzchd-1-5c6797-67kfz       2/2     Running   0          14m
elasticsearch-cdm-b3nqzchd-2-6657f4-wtprv       2/2     Running   0          14m
elasticsearch-cdm-b3nqzchd-3-588c65-clg7g       2/2     Running   0          14m
fluentd-2c7dg                                   1/1     Running   0          14m
fluentd-9z7kk                                   1/1     Running   0          14m
fluentd-br7r2                                   1/1     Running   0          14m
fluentd-fn2sb                                   1/1     Running   0          14m
fluentd-pb2f8                                   1/1     Running   0          14m
fluentd-zqgqx                                   1/1     Running   0          14m
kibana-7fb4fd4cc9-bvt4p                         2/2     Running   0          14m
----

_Fluentd_ *Pods* は、 *DaemonSet* としてデプロイされます。*DaemonSet* は、特定の *Pods* が、クラスタ内の特定の *Nodes* で常に実行されるための仕組みです。:


[source,bash,role="execute"]
----
oc get daemonset -n openshift-logging
----

以下のようなものを見ることができます。:

----
NAME      DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR            AGE
fluentd   9         9         9       9            9           kubernetes.io/os=linux   94s
----

クラスタ内の *Node* ごとに1つの `fluentd` *Pod* が必要です。
*Master* も *Node* であり、`fluentd` はそこでも様々なログを読み取るために実行されることを覚えておいてください。

また、ElasticSearch 用のストレージが自動的にプロビジョニングされていることがわかります。
このプロジェクトの *PersistentVolumeClaim* オブジェクトにクエリを実行すると、新しいストレージが表示されます。

[source,bash,role="execute"]
----
oc get pvc -n openshift-logging
----

以下のようなものが見えるはずです。:

----
NAME                                         STATUS   VOLUME                                     CAPACITY   ACCESS
MODES   STORAGECLASS                  AGE
elasticsearch-elasticsearch-cdm-ggzilasv-1   Bound    pvc-f3239564-389c-11ea-bab2-06ca7918708a   100Gi      RWO
        ocs-storagecluster-ceph-rbd   15m
elasticsearch-elasticsearch-cdm-ggzilasv-2   Bound    pvc-f324a252-389c-11ea-bab2-06ca7918708a   100Gi      RWO
        ocs-storagecluster-ceph-rbd   15m
elasticsearch-elasticsearch-cdm-ggzilasv-3   Bound    pvc-f326aa7d-389c-11ea-bab2-06ca7918708a   100Gi      RWO
        ocs-storagecluster-ceph-rbd   15m
----		

[NOTE]
====
Metrics ソリューションの場合と同様に、Logging の構成( `CR` )で適切な `NodeSelector` を定義して、Logging コンポーネントが infra ノードにしかデプロイされないようにしています。
つまり、`DaemonSet` は FluentD が *すべての* ノードで実行されることを保証しています。
そうでなければ、すべてのコンテナログをキャプチャすることはできません。
====

#### _Kibana_ にアクセスする

前述の通り、_Kibana_ はフロントエンドであり、ユーザーや管理者が OpenShift Logging スタックにアクセスするためのインターフェイスです。
_Kibana_ ユーザーインターフェースにアクセスするには、まず Kibana の *Service* を公開するために設定された *Route* を見て、そのパブリックアクセス URL を調べます。:

_Kibana_ route を見つけてアクセスするには:

1. OpenShift console から、 `Networking` → `Routes` ページをクリックします。

2. `openshift-logging` プロジェクトを選択します。

3. `Kibana` route をクリックします。

4. `Location` フィールドで、表示されている URL をクリックします。

5.  SSL 証明書をアクセプトします。

あるいは、コマンドラインから取得することもできます。:

[source,bash,role="execute"]
----
oc get route -n openshift-logging
----

以下のようなものが見えるはずです。:

----
NAME     HOST/PORT                                                           PATH   SERVICES   PORT    TERMINATION          WILDCARD
kibana   kibana-openshift-logging.{{ ROUTE_SUBDOMAIN }}          kibana     <all>   reencrypt/Redirect   None
----

または、control+click  をクリックすることができます。:

https://kibana-openshift-logging.{{ ROUTE_SUBDOMAIN }}

EFK インストールの一部として設定されている特別な認証プロキシがあり、その結果、Kibana はアクセスに OpenShift の資格情報を必要とします。

OpenShift Console に cluster-admin ユーザーとして認証済みのため、Kibana の管理画面が表示されます。

#### _Kibana_ を使ってクエリを行う

_Kibana_ の Web インターフェースが立ち上がったら、クエリを実行できるようになります。
_Kibana_ は、クラスタから送られてくるすべてのログを問い合わせるための強力なインターフェイスをユーザに提供します

デフォルトでは、_Kibana_　は過去15分以内に受信したすべてのログを表示します。
この時間間隔は右上で変更できます。
ログメッセージはページの中央に表示されます。
受信したすべてのログメッセージは、ログメッセージの内容に基づいてインデックス化されます。
各メッセージには、そのログメッセージに関連付けられたフィールドがあります。
個々のメッセージを構成するフィールドを見るには、ページの中央にある各メッセージの側面にある矢印をクリックします。
これにより、含まれているメッセージ フィールドが表示されます。

まず、デフォルトのインデックスパターンを `.all` に設定します。
左側から上に向かって、ドロップダウンメニューで `.all` のインデックスパターンを選択します。

メッセージに表示するフィールドを選択するには、左側の `Available Fields` ラベルの手前を見てください。
その下には選択可能なフィールドがあり、画面の中央に表示されます。
利用可能なフィールド `Available Fields` の下にある `hostname` フィールドを見つけて、 `add` をクリックします。
これで、メッセージペインに各メッセージのホスト名が表示されることに気づくでしょう。
これ以外にもフィールドを追加することができます。 `kubernetes.pod_name` と `message` の `add` ボタンをクリックします。

ログに対するクエリを作成するには、検索ボックスの右下にある `Add a filter +` リンクを使用することができます。
これにより、メッセージのフィールドを使ってクエリを作成することができます。
例えば、 `openshift-logging` namespace のすべてのログメッセージを見たい場合、以下のようにします。:

1. `Add a filter +` をクリックします。

2. `Fields` インプットボックスで、 `kubernetes.namespace_name` とタイプします。
クエリをビルドするための全ての可能なフィールドがある事に注目してください。

3. 次に、 `is` を選択します。

4. `Value` フィールドで、 `openshift-logging`　とタイプします。

5. "Save" ボタンをクリックします。

さて、画面の中央には `openshift-logging` namespace にあるすべてのポッドからのログが表示されているはずです。

もちろん、さらにフィルタを追加してクエリを絞り込むこともできます。

Kibanaでは、クエリを保存して後で使えるようにすることができます。クエリを保存するには、以下のようにします。:

1. 画面上部の `Save` をクリックする。

2. 保存したい名前を入力します。ここでは、`openshift-logging Namespace` と入力します。

一度保存しておけば、後で `Open` ボタンを押してこのクエリを選択することで利用することができます。

時間をかけて _Kibana_ のページを探索し、より多くのクエリを追加したり実行したりして経験を積んでください。
これは本番環境のクラスタを使用する際に役立つでしょう。
探しているログをこのコンソールから取得することができるようになります。
